{
  "id": "599dcc50-4f74-4f19-b045-9a8f77603396",
  "source": "CS 493 project presentation.pdf",
  "source_type": "pdf",
  "text": "Supervised Machine Learning Predicting Store Sales The Fellas Elesey Razumovskiy Shawyan Tabari Judah Tanninen Sales Data 02The Competition & Data \u25cfTrain a model that can predict future sales \u25cfLarge data set with over 3 million rows in training set \u25cfData set is Time Series \u25cbCollected at regular intervals \u25cbHas Seasonality and cyclical changes \u25cfAdditional data not in training data \u25cbHolidays \u25cbPrice of oil 03Data Science The Setup \u25cfDay to day fluctuation is large, with multiple cycles \u25cbWeekly, Monthly, Yearly \u25cfMultiple stores = every date is repeated \u25cboil prices are per day \u25cfSeparating the components and training the model on each component could improve over\ufb01tting All this means there is a lot of data pre-processing needed to train a good model 04 The Setup Processing The Data \u25cfSince the data is cyclical can condense data to a single year \u25cbreduces training time \u25a0iterate faster \u25cbcould help with over\ufb01tting \u25cfMake use of additional data \u25cbHoliday information, affects sales drastically, converted to a simple is_holiday column \u25cbOil Prices, Ecuador is an oil-dependent country and it's economical health is highly vulnerable to shocks in oil prices (Kaggle) This Gives us the following \u25cfCondense/trim data set \u25cfPrevent data leakage by performing steps inside Cross Validation Folds \u25cbeg. min-max scaler must be done for each fold separately 05 The Setup Finding the best Model Regression VS Classi\ufb01cation \u25cfPredicting quantity \u25cbMeans Model = regression \u25cfThe data is setup for a supervised model as well since we have a target Which Model to use \u25cfGradient boosting \u25cfLinear Regression \u25cfDecision Tree Regressor \u25cfRandom Forest 06Visualization Options Data Prep There is a wide array of options in regards to viewing the dataset, both before and after performing the desired \ufb01t. These include: 3D Plots MatLAB Graph Line Chart Histogram Pie Chart Bar Chart Box Plot The Fit 07Specify Year for Fine tuning You can specify the year to gather the data from. Pre FitCon\ufb01gurable Fit The User can perform the \ufb01t and adjust the options as desired for a wide variety of parameters. This includes the strategy set for the Imputers, the regression model being chosen, as well as the hyperparameters for the \ufb01t Choose Hyperparameters Choose from a variety of di\ufb00erent hyperparameters, depending on the chosen regression model Pre FitCustomize your Strategy Use di\ufb00erent \u2018Strategy\u2019 Parameters for the imputer Pre Fit The Fit 08Visualize your \ufb01t In addition, you can view your calculated error score and export the CSV for Kaggle submission as well Post FitCon\ufb01gurable Fit In addition to the specifying the regression model and con\ufb01gurable options, there is a wide variety of di\ufb00erent output and visuals to accompany the data Choose Regression Model Choose from four di\ufb00erent regression models to perform \ufb01t with Pre Fit 09 Performance Optimizing The Model Randomized and Grid Search Cross Validation \u25cfRandomized Search took a very long time on the data set, especially when using entire time range \u25cfGrid Search is faster, with multiple models to test speed is important Parameters \u25cfDepth \u25cfNumber Of Estimators \u25cfLeaf \u25cfLearning Rate 010 Performance Model Performance 1 3 Scoring In our program, we used R2 scoring, for the following reasons: \u25cfR2 Score is a standardized way to compare performance of models using GridSearchCV \u25cfR2 Score gives us proportion of variance between target and non-target columns Kaggle Score On our second submission to kaggle, we received a Root Mean Squared Logarithmic Error of 0.63843. This got us 453rd place on the competition, or the 64th percentile. 2 R2 Score The highest R2 score we were able to achieve was with a decision tree regression model. This model resulted in an R2 score of 0.898. Questions? The Fellas Joe Pesci Al Pacino Robert Deniro Sources https://www.marketwatch.com/story/youre-saving-all-wrong-if-you-die-with-a-pile-of-money-2020-07-28 https://www.researchgate.net/profile/Janusz-Szwabinski/publication/335951155/figure/fig1/AS:1022962757017605@1620904735879/Comparison-between-a-r andom-forest-and-b-gradient-boosting-methods-In-the-random.png https://quantdare.com/wp-content/uploads/2014/09/decomp-example.png https://media.istockphoto.com/id/1383831579/vector/double-thumbs-up-emoticon.jpg?s=612x612&w=0&k=20&c=gk_PkPyFLeQCB69U8vhxmzlyikncetntRGfR ghJTEiM= Any other images used are our own or generated using Google Duet AI",
  "summary": "The provided content is centered on a supervised machine learning project aimed at predicting future store sales. This initiative involves a comprehensive dataset with time series characteristics and ancillary data, such as holidays and oil prices. The analysis outlines various aspects of the setup, data processing, model selection, and performance optimization.\n\n### Main Topics and Themes\n\n1. **Supervised Machine Learning and Time Series Analysis**:\n   - The focus is on leveraging supervised machine learning to forecast sales using a large time series dataset. This involves understanding cyclical and seasonal patterns to improve prediction accuracy.\n\n2. **Data Pre-processing and Feature Engineering**:\n   - Essential tasks include condensing data to account for cyclical trends, such as weekly, monthly, and yearly cycles, and incorporating non-training data like holidays and oil prices to enhance model performance.\n\n3. **Model Selection and Evaluation**:\n   - The project discusses various regression models, including gradient boosting, linear regression, decision tree regressor, and random forest, evaluating their suitability using R2 scores and other error metrics.\n\n4. **Performance Optimization Techniques**:\n   - Emphasis is on techniques like Randomized and Grid Search for hyperparameter tuning, critical for optimizing model performance on large datasets.\n\n5. **Visualization and Data Interpretation**:\n   - Various visualization tools are highlighted to aid in understanding the dataset and interpret model results, showing a commitment to enhancing interpretability and transparency.\n\n### Arguments, Evidence, or Claims\n\n- **Impact of Data Features**: The inclusion of additional data like holidays and oil prices is argued as a critical element that significantly impacts sales predictions. This demonstrates awareness of external economic factors influencing retail environments.\n  \n- **Model Evaluation Metrics**: The use of R2 scoring as a standardized evaluation metric is cited, suggesting its importance in quantifying model accuracy and guiding iterative improvements.\n\n- **Model Performance Rankings**: The document claims success in achieving a notable R2 score with a decision tree regression model, reinforcing the validity of their modeling approach despite facing strong competition as indicated by Kaggle rankings.\n\n### Key Entities, People, or Organizations Mentioned\n\n- **The Fellas**: A team or group likely comprising Elesey Razumovskiy, Shawyan Tabari, and Judah Tanninen, who have undertaken this machine learning project.\n  \n- **Supporting Technologies and Platforms**: References to tools like Kaggle for competition and visualization platforms like MatLab indicate the technological framework employed in this analysis.\n\n- **Cultural References**: Names like Joe Pesci, Al Pacino, Robert De Niro are humorously mentioned, possibly to add a relatable, informal tone to the text.\n\n### Conclusions or Recommendations\n\n- **Data Preparation Strategy**: Advocating for detailed data pre-processing, including feature engineering and appropriate scaling techniques within cross-validation folds to prevent data leakage and overfitting.\n\n- **Model Tuning and Validation**: Recommendations include fine-tuning models using cross-validation techniques and exploring various regression models to find the best fit for the data.\n\n### Overall Purpose and Intended Audience\n\nThe content is primarily educational, aimed at data scientists, machine learning practitioners, or analysts working with sales forecasting or similar predictive analytics tasks. Its purpose is to share insights and methodologies from a practical machine learning project, likely encouraging others to adopt or adapt these strategies for their own predictive modeling challenges.\n\n### Insightful Analysis\n\nThis text underscores the complexity and multidimensional nature of predictive modeling in retail sales forecasting. It emphasizes the importance of integrating external data sources and seasonality considerations to capture real-world variability. Furthermore, it serves as a roadmap for others interested in entering data competitions like those on Kaggle, highlighting critical steps from data preparation to model tuning and evaluation. It reflects not only the technical skills required but also the strategic thinking necessary to effectively tackle large-scale data problems.",
  "sentiment": {
    "sentiment": "positive",
    "score": 0.9,
    "confidence": 0.95,
    "rationale": "The content reflects enthusiasm and success in a machine learning project, with positive remarks on model accuracy and strategic decisions in data handling. The humorous tone and detailed analysis further underscore the author's confidence and satisfaction with the project's outcomes, contributing to an overall optimistic sentiment."
  },
  "metadata": {
    "topics": [
      "Supervised Machine Learning and Time Series Analysis",
      "Data Pre-processing and Feature Engineering",
      "Model Selection and Evaluation",
      "Performance Optimization Techniques",
      "Visualization and Data Interpretation"
    ],
    "regions": [],
    "commodities": [
      "oil"
    ],
    "topic_details": {
      "main_topics": [
        "Supervised Machine Learning and Time Series Analysis",
        "Data Pre-processing and Feature Engineering",
        "Model Selection and Evaluation"
      ],
      "subtopics": [
        "Performance Optimization Techniques",
        "Visualization and Data Interpretation"
      ]
    },
    "geographical_details": {
      "countries": [],
      "regions": [],
      "cities": []
    },
    "commodity_details": {
      "resources": [
        "oil"
      ],
      "products": [],
      "financial_instruments": []
    },
    "temporal_details": {
      "time_period": [],
      "key_dates": []
    },
    "entities": [
      "Elesey Razumovskiy",
      "Shawyan Tabari",
      "Judah Tanninen",
      "Kaggle"
    ]
  },
  "timestamp": "2025-04-09T00:07:14.901549"
}